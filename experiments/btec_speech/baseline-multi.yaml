label: 'baseline-multi'
description: "multi-speaker baseline on BTEC"

dropout_rate: 0.5
cell_size: 256
attn_size: 256
embedding_size: 256

layers: 2
bidir: True
use_lstm: True
weight_scale: null

data_dir: experiments/btec_speech/data
model_dir: experiments/btec_speech/baseline_multi
batch_size: 64

train_prefix: train.concat  # Michel, Philippe, Loic, Marion, Helene, Fabienne
dev_prefix: dev.Agnes       # different speaker
#max_train_size: 20000      # TODO: shuffle entire training set before training

optimizer: 'adam'
learning_rate: 0.001

steps_per_checkpoint: 1000
steps_per_eval: 1000

max_gradient_norm: 5.0
max_steps: 30000
batch_mode: 'standard'
read_ahead: 10

encoders:
  - name: feats41
    embedding_size: 41
    layers: 3
    time_pooling: [2, 2]
    pooling_avg: True
    binary: True
    attention_filters: 1
    attention_filter_length: 25
    max_len: 600
    input_layers: [256, 256]
    concat_last_states: True
    bidir_projection: True
    trainable_initial_states: False

decoders:
  - name: en
    layers: 2
    max_len: 25
    maxout: False
    input_attention: False
    use_previous_word: False
    vanilla: False
    state_zero: True
    use_lstm_state: False
    output_extra_proj: False
    attn_prev_word: False
    maxout_stride: null
    convolutions: null
