label: 'BTEC legacy'
description: "BTEC legacy config"

dropout_rate: 0.5
cell_size: 256
attn_size: 256
embedding_size: 256

layers: 2
bidir: True
use_lstm: True
weight_scale: null

data_dir: experiments/btec_text/data
model_dir: experiments/btec_text/legacy
batch_size: 64
dev_prefix: dev

optimizer: 'adam'
learning_rate: 0.001

steps_per_checkpoint: 1000
steps_per_eval: 1000

max_gradient_norm: 5.0
max_steps: 30000
batch_mode: 'standard'
read_ahead: 10

max_len: 50

encoders:
  - name: fr
    concat_last_states: True
    bidir_projection: True
    trainable_initial_states: False

decoders:
  - name: en
    maxout: False
    input_attention: False
    use_previous_word: False
    vanilla: False
    state_zero: True
    use_lstm_state: False
    output_extra_proj: False
    attn_prev_word: False
